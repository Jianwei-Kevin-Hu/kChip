{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Full Pipeline\n",
    "\n",
    "**Inputs**: \n",
    "- config file\n",
    "- image files\n",
    "- well mask file\n",
    "\n",
    "**Outputs**:\n",
    "- droplets DataFrame (csv) \n",
    "- wells DataFrame (csv)\n",
    "- condensed DataFrame (csv)\n",
    "- jupyter notebook pre-loaded with basic quality control plots\n",
    "\n",
    "We have built all the necessary parts in other python notebooks and moved code to kchip_v0 package. Now, implement each step. \n",
    "\n",
    "#### Step 1: Create droplets DataFrame\n",
    "The droplets dataFrame contains information of all droplets in the pre-merge image set. We need to compute and store:\n",
    "- the RGB information of each droplet\n",
    "- the cluster and cluster label of each droplet\n",
    "- the location of each droplet\n",
    "- the well ID of each droplet\n",
    "\n",
    "All of these steps can be found in the \"Putting it together\" notebook. \n",
    "\n",
    "#### Step 2: Create wells DataFrame\n",
    "- Loop through post-merge images and identify wells\n",
    "- Map post-merge wells to pre-merge wells\n",
    "- Condense outputs to final dataframe\n",
    "\n",
    "All of these steps can be found in the \"Registration\" notebook and Final Outputs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Imports and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "barcodes:\n",
      "  cluster:\n",
      "    eps: 0.01\n",
      "    min_samples: 10\n",
      "    offset:\n",
      "    - 600\n",
      "    - 600\n",
      "    - 600\n",
      "    points_to_cluster: 2000\n",
      "  path: Notes.xlsx\n",
      "image:\n",
      "  base_path: Chip24_data/\n",
      "  bugs: 0\n",
      "  dyes:\n",
      "  - 1\n",
      "  - 3\n",
      "  - 2\n",
      "  names:\n",
      "    premerge: Chip24_premerge\n",
      "    t0: Chip24_t0\n",
      "    t1: Chip24_t1\n",
      "    t2: Chip24_t2\n",
      "  overlap: 0.05\n",
      "  pixel_size: 6.5\n",
      "  size: 1024\n",
      "  well_start_image:\n",
      "  - 1\n",
      "  - 1\n",
      "  well_start_xy:\n",
      "  - 518\n",
      "  - 434\n",
      "well_mask:\n",
      "  filename: Well Masks/k2_mask.tif\n",
      "  pixel_size: 8.33625\n",
      "  well_start_xy:\n",
      "  - 242\n",
      "  - 378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# basic imports \n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Append top level directory with kchip package\n",
    "\n",
    "\n",
    "# kchip imports\n",
    "import io as kchip_io\n",
    "import analyze as kchip_analyze\n",
    "\n",
    "# Other\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in config file\n",
    "with open('config24.yml', 'r') as ymlfile:\n",
    "    config = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "    \n",
    "print (yaml.dump(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 14\n",
    "plt.rcParams['axes.spines.right']=False\n",
    "plt.rcParams['axes.spines.top']=False\n",
    "\n",
    "plt.rcParams['axes.linewidth']=3\n",
    "plt.rcParams['axes.labelsize']=fontsize\n",
    "plt.rcParams['lines.linewidth']=2\n",
    "plt.rcParams['xtick.labelsize']=fontsize\n",
    "plt.rcParams['ytick.labelsize']=fontsize\n",
    "plt.rcParams['axes.titlesize'] = fontsize\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Helvetica']\n",
    "plt.rcParams['font.size']=fontsize\n",
    "plt.rcParams['xtick.major.width']=1.5\n",
    "plt.rcParams['ytick.major.width']=1.5\n",
    "plt.rcParams['contour.negative_linestyle'] = 'solid'\n",
    "\n",
    "plt.rcParams['savefig.bbox']='Tight'\n",
    "plt.rcParams['pdf.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create droplets DataFrame\n",
    "- Initialize from images\n",
    "- Identify droplets in the same well from fit to masks\n",
    "- Cluster\n",
    "- Map apriori labels to clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating droplets from: 10,1\n",
      "Creating droplets from: 10,2\n",
      "Creating droplets from: 10,3\n",
      "Creating droplets from: 10,4\n",
      "Creating droplets from: 10,5\n",
      "Creating droplets from: 10,6\n",
      "Creating droplets from: 1,1\n",
      "Creating droplets from: 1,2\n",
      "Creating droplets from: 1,3\n",
      "Creating droplets from: 1,4\n",
      "Creating droplets from: 1,5\n",
      "Creating droplets from: 1,6\n",
      "Creating droplets from: 1,7\n",
      "Creating droplets from: 2,1\n",
      "Creating droplets from: 2,2\n",
      "Creating droplets from: 2,3\n",
      "Creating droplets from: 2,4\n",
      "Creating droplets from: 2,5\n",
      "Creating droplets from: 2,6\n",
      "Creating droplets from: 2,7\n",
      "Creating droplets from: 3,1\n",
      "Creating droplets from: 3,2\n",
      "Creating droplets from: 3,3\n",
      "Creating droplets from: 3,4\n",
      "Creating droplets from: 3,5\n",
      "Creating droplets from: 3,6\n",
      "Creating droplets from: 3,7\n",
      "Creating droplets from: 4,1\n",
      "Creating droplets from: 4,2\n",
      "Creating droplets from: 4,3\n",
      "Creating droplets from: 4,4\n",
      "Creating droplets from: 4,5\n",
      "Creating droplets from: 4,6\n",
      "Creating droplets from: 5,1\n",
      "Creating droplets from: 5,2\n",
      "Creating droplets from: 5,3\n"
     ]
    }
   ],
   "source": [
    "# Initialize droplets DataFrame from images\n",
    "droplets, rotation_theta = kchip_analyze.initialize_droplets(config)\n",
    "\n",
    "print ('Rotation (degrees): ', rotation_theta*180/np.pi)\n",
    "\n",
    "# Identify droplets in the same well from fit to masks\n",
    "droplets = kchip_analyze.fit_droplets_to_mask(config,droplets,rotation_theta)\n",
    "\n",
    "# Cluster droplets and map apriori labels to clusters\n",
    "droplets, centroids = kchip_analyze.identify_clusters(config,droplets,show=1)\n",
    "\n",
    "print ('Total droplets identified: ', droplets.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create wells DataFrame\n",
    "- Create pre-merge wells dataFrame\n",
    "- Loop through post-merge images and identify wells\n",
    "- Map post-merge wells to pre-merge wells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Identify premerge wells\n",
    "pre_wells = droplets.groupby(['IndexX','IndexY','Well_ID'],as_index=False)[['ImageX','ImageY','Edge']].mean()\n",
    "\n",
    "# List of timepoints\n",
    "timepoints = ['t'+str(i) for i in range(3)]\n",
    "\n",
    "# Analyze data for each timepoint\n",
    "pre_post_all = []\n",
    "for timepoint in timepoints:\n",
    "    print ('Now analyzing timepoint: ', timepoint)\n",
    "    # Identify postmerge wells and map to pre-merge wells\n",
    "    pre_post_all.append(kchip_analyze.map_pre_to_post(config,timepoint,pre_wells))\n",
    "    pre_post_all[-1].to_csv(timepoint+'.csv')\n",
    "\n",
    "# Condense output\n",
    "condensed = kchip_analyze.stack_timepoints(droplets,pre_post_all,timepoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outputs\n",
    "droplets.to_csv('droplets.csv')\n",
    "condensed.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality control outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chip loading and global well positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_positions = pre_post_all[-1].groupby('Hash').mean()[['Pre_GlobalX','Pre_GlobalY']].values\n",
    "edge = pre_post_all[-1].groupby('Hash').mean()['Pre_Edge'].values\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,10))\n",
    "\n",
    "axes.plot(well_positions[:,0],-well_positions[:,1],'.',ms=2)\n",
    "axes.plot(well_positions[edge,0],-well_positions[edge,1],'.',ms=2)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot by total droplets in well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by_count(df,ax):\n",
    "    for item in df['Total'].unique():\n",
    "        pos = df[(df['Total']==item)][['Pre_GlobalX','Pre_GlobalY']].values\n",
    "        ax.plot(pos[:,0],-pos[:,1],'.',ms=2)\n",
    "    return ax\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(10,10))\n",
    "        \n",
    "condensed[['Hash','Total','t2_Area']] \\\n",
    "    .merge(pre_post_all[-1][['Hash','Pre_GlobalX','Pre_GlobalY','Pre_Edge']],on='Hash') \\\n",
    "    .pipe(plot_by_count,ax=axes) \n",
    "    \n",
    "axes.legend(condensed['Total'].unique(),loc=2,bbox_to_anchor=(1.05,1))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot area over chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "data = condensed[['Hash','Total','t2_Area']] \\\n",
    "    .merge(pre_post_all[-1][['Hash','Pre_GlobalX','Pre_GlobalY','Pre_Edge']],on='Hash') \n",
    "\n",
    "width = 1e1\n",
    "bins = np.arange(0,2e3,width)\n",
    "\n",
    "bin_by_area = pd.cut(data['t2_Area'],bins)\n",
    "bin_label = dict([(item,i) for i, item in enumerate(bin_by_area.unique().sort_values())])\n",
    "\n",
    "data['Area_Bin']=[bin_label[item] for item in bin_by_area]\n",
    "\n",
    "cmap = colors.LinearSegmentedColormap.from_list('', ['green','yellow','red','violet'],N=data['Area_Bin'].max())\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(20,10))\n",
    "axes[0].scatter(data['Pre_GlobalX'],-data['Pre_GlobalY'],c=data['Area_Bin'],cmap=cmap,marker='.',s=10,alpha=1)\n",
    "axes[0].axis('off')\n",
    "\n",
    "invert_label = {v: k for k, v in bin_label.items()}\n",
    "\n",
    "for label in invert_label.keys():\n",
    "    if invert_label[label]==invert_label[label]:\n",
    "        axes[1].bar(invert_label[label].mid,(data['Area_Bin']==label).sum(),width=width,color=cmap(label))\n",
    "\n",
    "axes[1].set_xlabel('Area')\n",
    "axes[1].set_ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "p = sns.pointplot(data=droplets.groupby('Label').count().reset_index(),x='Label',y='RX',join=False)\n",
    "\n",
    "p.set_xticklabels(p.get_xticklabels(),rotation=90)\n",
    "p.set_ylim([0,droplets.groupby('Label').count()['RX'].max()*1.5]);\n",
    "p.set_ylabel('Count')\n",
    "p.set_title('Representation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms of GFP and Area values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = condensed.filter(regex='t\\d+(?!_)').columns.values\n",
    "\n",
    "fig, axes = plt.subplots(1,len(timepoints),figsize=(4*len(timepoints),4))\n",
    "\n",
    "bins = np.arange(0,1e4,1e2)\n",
    "\n",
    "for ax, t in zip(axes,timepoints):\n",
    "    ax.hist(condensed[t].dropna(),bins=bins)\n",
    "    ax.set_xlabel('GFP Fluorescence')\n",
    "    ax.set_ylabel('Counts')\n",
    "    ax.set_title('Signal at '+t)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = condensed.filter(regex='t\\d+_Area').columns.values\n",
    "\n",
    "fig, axes = plt.subplots(1,len(timepoints),figsize=(4*len(timepoints),4))\n",
    "\n",
    "bins = np.arange(0,2e3,1e1)\n",
    "\n",
    "for ax, t in zip(axes,timepoints):\n",
    "    ax.hist(condensed[t].dropna(),bins=bins)\n",
    "    ax.set_xlabel('Area')\n",
    "    ax.set_ylabel('Counts')\n",
    "    ax.set_title('Area at '+t[:-5])\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
